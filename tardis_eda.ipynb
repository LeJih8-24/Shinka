{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a5031c",
   "metadata": {},
   "source": [
    "EPITECH PROJECT 2025\n",
    "TARDIS\n",
    "tardis_eda\n",
    "-- Cleans data and retrieve it into cleaned_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c75201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "\n",
    "clean_names = [\n",
    "    \"BORDEAUX ST JEAN\",\n",
    "    \"LA ROCHELLE VILLE\",\n",
    "    \"PARIS MONTPARNASSE\",\n",
    "    \"QUIMPER\",\n",
    "    \"TOURS\",\n",
    "    \"ST PIERRE DES CORPS\",\n",
    "    \"ST MALO\",\n",
    "    \"NANTES\",\n",
    "    \"PARIS EST\",\n",
    "    \"STRASBOURG\",\n",
    "    \"DUNKERQUE\",\n",
    "    \"LILLE\",\n",
    "    \"PARIS VAUGIRARD\",\n",
    "    \"RENNES\",\n",
    "    \"TOURCOING\",\n",
    "    \"CHAMBERY CHALLES LES EAUX\",\n",
    "    \"LYON PART DIEU\",\n",
    "    \"MONTPELLIER\",\n",
    "    \"MULHOUSE VILLE\",\n",
    "    \"NICE VILLE\",\n",
    "    \"PARIS LYON\",\n",
    "    \"BARCELONA\",\n",
    "    \"GENEVE\",\n",
    "    \"MADRID\",\n",
    "    \"BREST\",\n",
    "    \"POITIERS\",\n",
    "    \"TOULOUSE MATABIAU\",\n",
    "    \"MARNE LA VALLEE\",\n",
    "    \"MARSEILLE ST CHARLES\",\n",
    "    \"FRANCFORT\",\n",
    "    \"ANGOULEME\",\n",
    "    \"METZ\",\n",
    "    \"PARIS NORD\",\n",
    "    \"BELLEGARDE (AIN)\",\n",
    "    \"MACON LOCHE\",\n",
    "    \"PERPIGNAN\",\n",
    "    \"DOUAI\",\n",
    "    \"VALENCE ALIXAN TGV\",\n",
    "    \"LAUSANNE\",\n",
    "    \"ANGERS SAINT LAUD\",\n",
    "    \"STUTTGART\",\n",
    "    \"LAVAL\",\n",
    "    \"NANCY\",\n",
    "    \"BESANCON FRANCHE COMTE TGV\",\n",
    "    \"GRENOBLE\",\n",
    "    \"NIMES\",\n",
    "    \"SAINT ETIENNE CHATEAUCREUX\",\n",
    "    \"ITALIE\",\n",
    "    \"ZURICH\",\n",
    "    \"VANNES\",\n",
    "    \"ANNECY\",\n",
    "    \"AVIGNON TGV\",\n",
    "    \"MADRID\",\n",
    "    \"LE MANS\",\n",
    "    \"ST MALO\",\n",
    "    \"ARRAS\",\n",
    "    \"DIJON VILLE\",\n",
    "    \"LE CREUSOT MONTCEAU MONTCHANIN\",\n",
    "    \"REIMS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586134b",
   "metadata": {},
   "source": [
    "Takes data from dataframe and return the number of cancelled trains by departure station into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc41ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[\"Departure station\"] = (\n",
    "        df[\"Departure station\"].astype(str).str.upper().str.strip()\n",
    "    )\n",
    "    df[\"Average journey time\"] = pd.to_numeric(\n",
    "        df[\"Average journey time\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    df_grouped = (\n",
    "        df.groupby(\"Departure station\")[\"Number of cancelled trains\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    stations = df_grouped[\"Departure station\"].tolist()\n",
    "    delays = df_grouped[\"Number of cancelled trains\"].tolist()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(stations, delays, marker=\"o\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Retards moyens par station de dÃ©part\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Retard moyen (min)\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a901",
   "metadata": {},
   "source": [
    "This function returns a dictionary of mean values of all the numeric columns grouped by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e75dcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_station(df: pd.DataFrame):\n",
    "    dic_values = {}\n",
    "    temp_dic = {}\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df_grouped = df.groupby(\"Departure station\")[numeric_columns].mean().reset_index()\n",
    "    to_csv(df_grouped, path=\"grouped.csv\")\n",
    "    for elt in df_grouped[\"Departure station\"]:\n",
    "        tab = df_grouped[df_grouped[\"Departure station\"] == elt].iloc[0]\n",
    "        for i in range(1, len(tab)):\n",
    "            temp_dic[df_grouped.columns[i]] = tab[i]\n",
    "        dic_values[elt] = temp_dic\n",
    "    return dic_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55572d1b",
   "metadata": {},
   "source": [
    "This group of functions return the same as get_data_station except that the values are stored in list and not they're not getting meaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a0d2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dic(line, columns, dic, table_of_dup):\n",
    "    name = line[\"Departure station\"]\n",
    "    temp_tab = [line[\"Date\"], line[\"Departure station\"], line[\"Arrival station\"]]\n",
    "    if name == \"None\" or temp_tab in table_of_dup:\n",
    "        return 0\n",
    "    table_of_dup.append(temp_tab)\n",
    "    if name not in dic:\n",
    "        dic[name] = {}\n",
    "    if \"Arrival stations\" not in dic[name]:\n",
    "        dic[name][\"Arrival stations\"] = []\n",
    "    else:\n",
    "        dic[name][\"Arrival stations\"].append(line[\"Arrival station\"])\n",
    "    if \"Dates\" not in dic[name]:\n",
    "        dic[name][\"Dates\"] = []\n",
    "    else:\n",
    "        dic[name][\"Dates\"].append(temp_tab[0])\n",
    "    for elt in columns:\n",
    "        if elt not in dic[name]:\n",
    "            dic[name][elt] = []\n",
    "        dic[name][elt].append(line[elt])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_data_tab(df: pd.DataFrame):\n",
    "    dic = {}\n",
    "    table = []\n",
    "    df_sorted = df.sort_values(\"Departure station\")\n",
    "    numeric_columns = df_sorted.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for i in range(0, len(df_sorted)):\n",
    "        append_to_dic(df_sorted.iloc[i], numeric_columns, dic, table)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796515d",
   "metadata": {},
   "source": [
    "Read the csv given in path:\n",
    "- With the ; separator\n",
    "- Encoding in utf-8 to get good values\n",
    "- Disabled quoting so the quotes are automatically removed\n",
    "- Espacechar is \\\n",
    "- Skip on bad lines to avoid errors\n",
    "- Runs for python for better treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ef454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    final_dic = {}\n",
    "    lignes_corrigees = []\n",
    "\n",
    "    with open(filename, mode=\"r\", encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=';', quotechar='\"')\n",
    "        header = next(reader)\n",
    "        nb_columns = len(header)\n",
    "\n",
    "        for col in header:\n",
    "            final_dic[col] = []\n",
    "\n",
    "        buffer = \"\"\n",
    "        for line in f:\n",
    "            buffer += line\n",
    "            if buffer.count(\";\") >= nb_columns - 1:\n",
    "                try:\n",
    "                    row = next(csv.reader([buffer], delimiter=\";\", quotechar='\"'))\n",
    "                    row = [val.replace('\\n', ' | ').strip() for val in row]\n",
    "                    if len(row) == nb_columns:\n",
    "                        lignes_corrigees.append(row)\n",
    "                except csv.Error:\n",
    "                    buffer = \"\"\n",
    "                buffer = \"\"\n",
    "\n",
    "        for row in lignes_corrigees:\n",
    "            for i, val in enumerate(row):\n",
    "                final_dic[header[i]].append(val)\n",
    "    return pd.DataFrame(final_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325bd65",
   "metadata": {},
   "source": [
    "Write a dataframe to csv with the defaut path as test.csv, can be changed though.\n",
    "Added separator and disabled index to be exactly like the old csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fb08f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df: pd.DataFrame, path=\"test.csv\"):\n",
    "    df.to_csv(path, sep=\";\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f7d2c",
   "metadata": {},
   "source": [
    "Is valid date check if the date is on format YYYY-MM (REGEX BLBLBLBLBL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_date(date_str):\n",
    "        return bool(re.match(r'^\\d{4}-\\d{2}$', str(date_str).strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ebcde",
   "metadata": {},
   "source": [
    "This algorithm to get the closest match works for a list and a name:\n",
    "\n",
    "- Compare the name with all elements in the correct list\n",
    "- returns the best match with a distance <=1\n",
    "- return None if no good matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53975e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        return np.inf\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "\n",
    "\n",
    "def get_closest_match(name, correct_list):\n",
    "    if not name or not isinstance(name, str):\n",
    "        return \"None\"\n",
    "\n",
    "    name = name.strip().upper()\n",
    "    correct_list_cleaned = [n.strip().upper() for n in correct_list]\n",
    "\n",
    "    distances = [hamming_distance(name, ref) for ref in correct_list_cleaned]\n",
    "    min_distance = min(distances)\n",
    "\n",
    "    if min_distance <= 1:\n",
    "        best_match_index = distances.index(min_distance)\n",
    "        return correct_list[best_match_index]\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0fdca",
   "metadata": {},
   "source": [
    "This function clean data in three steps:\n",
    "- If the column is a comment or departure/arrival station it'll be cleaned by the function get_closest_match to return the correct name of the station, None for comments\n",
    "- If it is the date and miswritten, it'll take the line on top\n",
    "- If it is none of the above, it is certainly a numeric column so if Null value it is replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame):\n",
    "    for column in df.columns:\n",
    "        if column in [\"Departure station\", \"Arrival station\"] or \"comments\" in column:\n",
    "            print(column)\n",
    "            df[column] = (\n",
    "                df[column]\n",
    "                .fillna(\"\")\n",
    "                .apply(lambda x: get_closest_match(str(x), clean_names))\n",
    "            )\n",
    "        elif column == \"Date\":\n",
    "            df[column] = df[column].apply(lambda x: x if is_valid_date(x) else pd.NA)\n",
    "            df[column] = df[column].fillna(method=\"ffill\")\n",
    "        elif column == \"Service\":\n",
    "            df[column] = df[column].fillna(\"International\")\n",
    "        else:\n",
    "            df[column] = df[column].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d5c01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_program(df: pd.DataFrame):\n",
    "    data_values_dic = get_data_station(df)\n",
    "    data_values_tab = get_data_tab(df)\n",
    "    return data_values_dic, data_values_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15b1b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Lecture du fichier csv\n",
    "    df = read_csv(\"dataset.csv\")\n",
    "\n",
    "    # Nettoyage du tableau\n",
    "    clean_data(df)\n",
    "\n",
    "    # Convertir en csv\n",
    "    to_csv(df, path=\"cleaned_dataset.csv\")\n",
    "\n",
    "    # RÃ©cupÃ©ration des donnÃ©es\n",
    "    data_values_dic, data_values_tab = get_data_program(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23d480b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5535/1245369182.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method=\"ffill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departure station\n",
      "Arrival station\n",
      "Cancellation comments\n",
      "Departure delay comments\n",
      "Arrival delay comments\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
