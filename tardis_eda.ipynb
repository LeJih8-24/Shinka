{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a5031c",
   "metadata": {},
   "source": [
    "EPITECH PROJECT 2025\n",
    "TARDIS\n",
    "tardis_eda\n",
    "-- Cleans data and retrieve it into cleaned_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c75201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from dictionary_visualizer import visualiser_dictionnaire\n",
    "\n",
    "clean_names = [\n",
    "    \"BORDEAUX ST JEAN\",\n",
    "    \"LA ROCHELLE VILLE\",\n",
    "    \"PARIS MONTPARNASSE\",\n",
    "    \"QUIMPER\",\n",
    "    \"TOURS\",\n",
    "    \"ST PIERRE DES CORPS\",\n",
    "    \"ST MALO\",\n",
    "    \"NANTES\",\n",
    "    \"PARIS EST\",\n",
    "    \"STRASBOURG\",\n",
    "    \"DUNKERQUE\",\n",
    "    \"LILLE\",\n",
    "    \"PARIS VAUGIRARD\",\n",
    "    \"RENNES\",\n",
    "    \"TOURCOING\",\n",
    "    \"CHAMBERY CHALLES LES EAUX\",\n",
    "    \"LYON PART DIEU\",\n",
    "    \"MONTPELLIER\",\n",
    "    \"MULHOUSE VILLE\",\n",
    "    \"NICE VILLE\",\n",
    "    \"PARIS LYON\",\n",
    "    \"BARCELONA\",\n",
    "    \"GENEVE\",\n",
    "    \"MADRID\",\n",
    "    \"BREST\",\n",
    "    \"POITIERS\",\n",
    "    \"TOULOUSE MATABIAU\",\n",
    "    \"MARNE LA VALLEE\",\n",
    "    \"MARSEILLE ST CHARLES\",\n",
    "    \"FRANCFORT\",\n",
    "    \"ANGOULEME\",\n",
    "    \"METZ\",\n",
    "    \"PARIS NORD\",\n",
    "    \"BELLEGARDE (AIN)\",\n",
    "    \"MACON LOCHE\",\n",
    "    \"PERPIGNAN\",\n",
    "    \"DOUAI\",\n",
    "    \"VALENCE ALIXAN TGV\",\n",
    "    \"LAUSANNE\",\n",
    "    \"ANGERS SAINT LAUD\",\n",
    "    \"STUTTGART\",\n",
    "    \"LAVAL\",\n",
    "    \"NANCY\",\n",
    "    \"BESANCON FRANCHE COMTE TGV\",\n",
    "    \"GRENOBLE\",\n",
    "    \"NIMES\",\n",
    "    \"SAINT ETIENNE CHATEAUCREUX\",\n",
    "    \"ITALIE\",\n",
    "    \"ZURICH\",\n",
    "    \"VANNES\",\n",
    "    \"ANNECY\",\n",
    "    \"AVIGNON TGV\",\n",
    "    \"MADRID\",\n",
    "    \"LE MANS\",\n",
    "    \"ST MALO\",\n",
    "    \"ARRAS\",\n",
    "    \"DIJON VILLE\",\n",
    "    \"LE CREUSOT MONTCEAU MONTCHANIN\",\n",
    "    \"REIMS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586134b",
   "metadata": {},
   "source": [
    "Takes data from dataframe and return the number of cancelled trains by departure station into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc41ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[\"Departure station\"] = (\n",
    "        df[\"Departure station\"].astype(str).str.upper().str.strip()\n",
    "    )\n",
    "    df[\"Average journey time\"] = pd.to_numeric(\n",
    "\n",
    "        df[\"Average journey time\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    df_grouped = (\n",
    "        df.groupby(\"Departure station\")[\"Number of cancelled trains\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    stations = df_grouped[\"Departure station\"].tolist()\n",
    "    delays = df_grouped[\"Number of cancelled trains\"].tolist()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(stations, delays, marker=\"o\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Retards moyens par station de départ\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Retard moyen (min)\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a901",
   "metadata": {},
   "source": [
    "This function returns a dictionary of mean values of all the numeric columns grouped by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_station(df: pd.DataFrame):\n",
    "    dic_values = {}\n",
    "    temp_dic = {}\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df_grouped = df.groupby(\"Departure station\")[numeric_columns].mean().reset_index()\n",
    "    to_csv(df_grouped, path=\"grouped.csv\")\n",
    "    for elt in df_grouped[\"Departure station\"]:\n",
    "        tab = df_grouped[df_grouped[\"Departure station\"] == elt].iloc[0]\n",
    "        for i in range(1, len(tab)):\n",
    "            temp_dic[df_grouped.columns[i]] = tab[i]\n",
    "        dic_values[elt] = temp_dic\n",
    "    return dic_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55572d1b",
   "metadata": {},
   "source": [
    "This group of functions return the same as get_data_station except that the values are stored in list and not they're not getting meaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dic(line, columns, dic, table_of_dup):\n",
    "    name = line[\"Departure station\"]\n",
    "    temp_tab = [line[\"Date\"], line[\"Departure station\"], line[\"Arrival station\"]]\n",
    "    if name == \"None\" or temp_tab in table_of_dup:\n",
    "        return 0\n",
    "    table_of_dup.append(temp_tab)\n",
    "    if name not in dic:\n",
    "        dic[name] = {}\n",
    "    if \"Arrival stations\" not in dic[name]:\n",
    "        dic[name][\"Arrival stations\"] = []\n",
    "    else:\n",
    "        dic[name][\"Arrival stations\"].append(line[\"Arrival station\"])\n",
    "    if \"Dates\" not in dic[name]:\n",
    "        dic[name][\"Dates\"] = []\n",
    "    else:\n",
    "        dic[name][\"Dates\"].append(temp_tab[0])\n",
    "    for elt in columns:\n",
    "        if elt not in dic[name]:\n",
    "            dic[name][elt] = []\n",
    "        dic[name][elt].append(line[elt])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_data_tab(df: pd.DataFrame):\n",
    "    dic = {}\n",
    "    table = []\n",
    "    df_sorted = df.sort_values(\"Departure station\")\n",
    "    numeric_columns = df_sorted.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for i in range(0, len(df_sorted)):\n",
    "        append_to_dic(df_sorted.iloc[i], numeric_columns, dic, table)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796515d",
   "metadata": {},
   "source": [
    "Read the csv given in path:\n",
    "- With the ; separator\n",
    "- Encoding in utf-8 to get good values\n",
    "- Disabled quoting so the quotes are automatically removed\n",
    "- Espacechar is \\\n",
    "- Skip on bad lines to avoid errors\n",
    "- Runs for python for better treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ef454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_path):\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        sep=\";\",\n",
    "        encoding=\"utf-8\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        escapechar=\"\\\\\",\n",
    "        on_bad_lines=\"skip\",\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325bd65",
   "metadata": {},
   "source": [
    "Write a dataframe to csv with the defaut path as test.csv, can be changed though.\n",
    "Added separator and disabled index to be exactly like the old csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb08f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df: pd.DataFrame, path=\"test.csv\"):\n",
    "    df.to_csv(path, sep=\";\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ebcde",
   "metadata": {},
   "source": [
    "This algorithm to get the closest match works for a list and a name:\n",
    "\n",
    "- Compare the name with all elements in the correct list\n",
    "- returns the best match with a distance <=1\n",
    "- return None if no good matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53975e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        return np.inf\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "\n",
    "\n",
    "def get_closest_match(name, correct_list):\n",
    "    if not name or not isinstance(name, str):\n",
    "        return \"None\"\n",
    "\n",
    "    name = name.strip().upper()\n",
    "    correct_list_cleaned = [n.strip().upper() for n in correct_list]\n",
    "\n",
    "    distances = [hamming_distance(name, ref) for ref in correct_list_cleaned]\n",
    "    min_distance = min(distances)\n",
    "\n",
    "    if min_distance <= 1:\n",
    "        best_match_index = distances.index(min_distance)\n",
    "        return correct_list[best_match_index]\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0fdca",
   "metadata": {},
   "source": [
    "This function clean data in three steps:\n",
    "- If the column is a comment or departure/arrival station it'll be cleaned by the function get_closest_match to return the correct name of the station, None for comments\n",
    "- If it is the date and miswritten, it'll take the line on top\n",
    "- If it is none of the above, it is certainly a numeric column so if Null value it is replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame):\n",
    "    for column in df.columns:\n",
    "        if column in [\"Departure station\", \"Arrival station\"] or \"comments\" in column:\n",
    "            print(column)\n",
    "            if column in df.columns:\n",
    "                df[column] = (\n",
    "                    df[column]\n",
    "                    .fillna(\"\")\n",
    "                    .apply(lambda x: get_closest_match(str(x), clean_names))\n",
    "                )\n",
    "        elif column == \"Date\":\n",
    "            df[column] = df[column].fillna(method=\"ffill\")\n",
    "        else:\n",
    "            df[column] = df[column].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = read_csv(\"dataset.csv\")\n",
    "    print(\"Fichier lu.\")\n",
    "\n",
    "    clean_data(df)\n",
    "    print(\"Données nettoyées.\")\n",
    "\n",
    "    to_csv(df, path=\"cleaned_dataset.csv\")\n",
    "    print(\"Données sauvegardées dans test.csv.\")\n",
    "\n",
    "    data_values_dic = get_data_station(df)\n",
    "    data_values_tab = get_data_tab(df)\n",
    "    # show_data(df)\n",
    "\n",
    "    for elt in data_values_tab:\n",
    "        for i in range(0, len(data_values_tab[elt])):\n",
    "            print(f\"City: {elt}\", end=\"\")\n",
    "            print(\n",
    "                f\"{data_values_tab[elt]['Arrival stations'][i]} - {data_values_tab[elt]['Dates'][i]}\"\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
