{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a5031c",
   "metadata": {},
   "source": [
    "EPITECH PROJECT 2025\n",
    "TARDIS\n",
    "tardis_eda\n",
    "-- Cleans data and retrieve it into cleaned_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c75201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "\n",
    "clean_names = [\n",
    "    \"BORDEAUX ST JEAN\",\n",
    "    \"LA ROCHELLE VILLE\",\n",
    "    \"PARIS MONTPARNASSE\",\n",
    "    \"QUIMPER\",\n",
    "    \"TOURS\",\n",
    "    \"ST PIERRE DES CORPS\",\n",
    "    \"ST MALO\",\n",
    "    \"NANTES\",\n",
    "    \"PARIS EST\",\n",
    "    \"STRASBOURG\",\n",
    "    \"DUNKERQUE\",\n",
    "    \"LILLE\",\n",
    "    \"PARIS VAUGIRARD\",\n",
    "    \"RENNES\",\n",
    "    \"TOURCOING\",\n",
    "    \"CHAMBERY CHALLES LES EAUX\",\n",
    "    \"LYON PART DIEU\",\n",
    "    \"MONTPELLIER\",\n",
    "    \"MULHOUSE VILLE\",\n",
    "    \"NICE VILLE\",\n",
    "    \"PARIS LYON\",\n",
    "    \"BARCELONA\",\n",
    "    \"GENEVE\",\n",
    "    \"MADRID\",\n",
    "    \"BREST\",\n",
    "    \"POITIERS\",\n",
    "    \"TOULOUSE MATABIAU\",\n",
    "    \"MARNE LA VALLEE\",\n",
    "    \"MARSEILLE ST CHARLES\",\n",
    "    \"FRANCFORT\",\n",
    "    \"ANGOULEME\",\n",
    "    \"METZ\",\n",
    "    \"PARIS NORD\",\n",
    "    \"BELLEGARDE (AIN)\",\n",
    "    \"MACON LOCHE\",\n",
    "    \"PERPIGNAN\",\n",
    "    \"DOUAI\",\n",
    "    \"VALENCE ALIXAN TGV\",\n",
    "    \"LAUSANNE\",\n",
    "    \"ANGERS SAINT LAUD\",\n",
    "    \"STUTTGART\",\n",
    "    \"LAVAL\",\n",
    "    \"NANCY\",\n",
    "    \"BESANCON FRANCHE COMTE TGV\",\n",
    "    \"GRENOBLE\",\n",
    "    \"NIMES\",\n",
    "    \"SAINT ETIENNE CHATEAUCREUX\",\n",
    "    \"ITALIE\",\n",
    "    \"ZURICH\",\n",
    "    \"VANNES\",\n",
    "    \"ANNECY\",\n",
    "    \"AVIGNON TGV\",\n",
    "    \"MADRID\",\n",
    "    \"LE MANS\",\n",
    "    \"ST MALO\",\n",
    "    \"ARRAS\",\n",
    "    \"DIJON VILLE\",\n",
    "    \"LE CREUSOT MONTCEAU MONTCHANIN\",\n",
    "    \"REIMS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586134b",
   "metadata": {},
   "source": [
    "Takes data from dataframe and return the number of cancelled trains by departure station into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc41ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[\"Departure station\"] = (\n",
    "        df[\"Departure station\"].astype(str).str.upper().str.strip()\n",
    "    )\n",
    "    df[\"Average journey time\"] = pd.to_numeric(\n",
    "        df[\"Average journey time\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    df_grouped = (\n",
    "        df.groupby(\"Departure station\")[\"Number of cancelled trains\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    stations = df_grouped[\"Departure station\"].tolist()\n",
    "    delays = df_grouped[\"Number of cancelled trains\"].tolist()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(stations, delays, marker=\"o\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Retards moyens par station de dÃ©part\")\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.ylabel(\"Retard moyen (min)\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a901",
   "metadata": {},
   "source": [
    "This function returns a dictionary of mean values of all the numeric columns grouped by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_data_station(df: pd.DataFrame):\n",
    "    dic_values = {}\n",
    "    temp_dic = {}\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df_grouped = df.groupby(\"Departure station\")[numeric_columns].mean().reset_index()\n",
    "    to_csv(df_grouped, path=\"grouped.csv\")\n",
    "    for elt in df_grouped[\"Departure station\"]:\n",
    "        tab = df_grouped[df_grouped[\"Departure station\"] == elt].iloc[0]\n",
    "        for i in range(1, len(tab)):\n",
    "            temp_dic[df_grouped.columns[i]] = tab[i]\n",
    "        dic_values[elt] = temp_dic\n",
    "    return dic_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55572d1b",
   "metadata": {},
   "source": [
    "This group of functions return the same as get_data_station except that the values are stored in list and not they're not getting meaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dic(line, columns, dic, table_of_dup):\n",
    "    name = line[\"Departure station\"]\n",
    "    temp_tab = [line[\"Date\"], line[\"Departure station\"], line[\"Arrival station\"]]\n",
    "    if name == \"None\" or temp_tab in table_of_dup:\n",
    "        return 0\n",
    "    table_of_dup.append(temp_tab)\n",
    "    if name not in dic:\n",
    "        dic[name] = {}\n",
    "    if \"Arrival stations\" not in dic[name]:\n",
    "        dic[name][\"Arrival stations\"] = []\n",
    "    else:\n",
    "        dic[name][\"Arrival stations\"].append(line[\"Arrival station\"])\n",
    "    if \"Dates\" not in dic[name]:\n",
    "        dic[name][\"Dates\"] = []\n",
    "    else:\n",
    "        dic[name][\"Dates\"].append(temp_tab[0])\n",
    "    for elt in columns:\n",
    "        if elt not in dic[name]:\n",
    "            dic[name][elt] = []\n",
    "        dic[name][elt].append(line[elt])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_data_tab(df: pd.DataFrame):\n",
    "    dic = {}\n",
    "    table = []\n",
    "    df_sorted = df.sort_values(\"Departure station\")\n",
    "    numeric_columns = df_sorted.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for i in range(0, len(df_sorted)):\n",
    "        append_to_dic(df_sorted.iloc[i], numeric_columns, dic, table)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796515d",
   "metadata": {},
   "source": [
    "Read the csv given in path:\n",
    "- With the ; separator\n",
    "- Encoding in utf-8 to get good values\n",
    "- Disabled quoting so the quotes are automatically removed\n",
    "- Espacechar is \\\n",
    "- Skip on bad lines to avoid errors\n",
    "- Runs for python for better treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ef454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    final_dic = {}\n",
    "    lignes_corrigees = []\n",
    "\n",
    "    with open(filename, mode=\"r\", encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=';', quotechar='\"')\n",
    "        header = next(reader)\n",
    "        nb_columns = len(header)\n",
    "\n",
    "        for col in header:\n",
    "            final_dic[col] = []\n",
    "\n",
    "        buffer = \"\"\n",
    "        for line in f:\n",
    "            buffer += line\n",
    "            if buffer.count(\";\") >= nb_columns - 1:\n",
    "                try:\n",
    "                    row = next(csv.reader([buffer], delimiter=\";\", quotechar='\"'))\n",
    "                    row = [val.replace('\\n', ' | ').strip() for val in row]\n",
    "                    if len(row) == nb_columns:\n",
    "                        lignes_corrigees.append(row)\n",
    "                except Exception as e:\n",
    "                    if not e:\n",
    "                        print(e)\n",
    "                    buffer = \"\"\n",
    "                buffer = \"\"\n",
    "\n",
    "        for row in lignes_corrigees:\n",
    "            for i, val in enumerate(row):\n",
    "                final_dic[header[i]].append(val)\n",
    "    return pd.DataFrame(final_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325bd65",
   "metadata": {},
   "source": [
    "Write a dataframe to csv with the defaut path as test.csv, can be changed though.\n",
    "Added separator and disabled index to be exactly like the old csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb08f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df: pd.DataFrame, path=\"test.csv\"):\n",
    "    df.to_csv(path, sep=\";\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7034b9",
   "metadata": {},
   "source": [
    "Check if delay consistency is good:\n",
    "\n",
    "For exemple, if there is more trains delayed by 30 minutes than 15 minutes, which is not possible, the row delayed by 30mn is set to row delayed by 15mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_delay_consistency(row):\n",
    "        if row[\"Number of trains delayed > 30min\"] > row[\"Number of trains delayed > 15min\"]:\n",
    "            row[\"Number of trains delayed > 30min\"] = row[\"Number of trains delayed > 15min\"]\n",
    "        if row[\"Number of trains delayed > 60min\"] > row[\"Number of trains delayed > 30min\"]:\n",
    "            row[\"Number of trains delayed > 60min\"] = row[\"Number of trains delayed > 30min\"]\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f7d2c",
   "metadata": {},
   "source": [
    "Is valid date check if the date is on format YYYY-MM (REGEX BLBLBLBLBL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_date(date_str):\n",
    "    if not isinstance(date_str, str):\n",
    "        return False\n",
    "    if len(date_str) != 7 or date_str[4] != '-':\n",
    "        return False\n",
    "    try:\n",
    "        year = int(date_str[0:4])\n",
    "        month = int(date_str[5:7])\n",
    "        return 1 <= month <= 12 and year > 0\n",
    "    except Exception as e:\n",
    "        if not e:\n",
    "            print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ebcde",
   "metadata": {},
   "source": [
    "This algorithm to get the closest match works for a list and a name:\n",
    "\n",
    "- Compare the name with all elements in the correct list\n",
    "- returns the best match with a distance <=1\n",
    "- return None if no good matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53975e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        return np.inf\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "\n",
    "\n",
    "def get_closest_match(name, correct_list):\n",
    "    if not name or not isinstance(name, str):\n",
    "        return \"None\"\n",
    "\n",
    "    name = name.strip().upper()\n",
    "    correct_list_cleaned = [n.strip().upper() for n in correct_list]\n",
    "\n",
    "    distances = [hamming_distance(name, ref) for ref in correct_list_cleaned]\n",
    "    min_distance = min(distances)\n",
    "\n",
    "    if min_distance <= 1:\n",
    "        best_match_index = distances.index(min_distance)\n",
    "        return correct_list[best_match_index]\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0d031",
   "metadata": {},
   "source": [
    "Clean dataset if a mandatory column is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_mandatory(df, mandatory_cols):\n",
    "    df_clean = df.copy()\n",
    "    for col in mandatory_cols:\n",
    "        if col in df_clean.columns:\n",
    "            idx_to_drop = df_clean[\n",
    "                df_clean[col].isna() | (df_clean[col].astype(str).str.lower() == 'nan')\n",
    "            ].index\n",
    "            df_clean = df_clean.drop(index=idx_to_drop)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0fdca",
   "metadata": {},
   "source": [
    "This function clean data in three steps:\n",
    "- If the column is a comment or departure/arrival station it'll be cleaned by the function get_closest_match to return the correct name of the station, None for comments\n",
    "- If it is the date and miswritten, it'll take the line on top\n",
    "- If it is none of the above, it is certainly a numeric column so if Null value it is replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory = [\"Date\", \"Service\", \"Departure station\", \"Arrival station\"]\n",
    "\n",
    "def clean_data(df: pd.DataFrame):\n",
    "    \n",
    "    df = missing_mandatory(df, mandatory)\n",
    "    df = df.drop_duplicates(\n",
    "        subset=mandatory,\n",
    "        keep=\"first\"\n",
    "    )\n",
    "    # 2. Correction par colonne\n",
    "    for column in df.columns:\n",
    "        col_lower = column.lower()\n",
    "\n",
    "        # Nettoyage des stations + commentaires\n",
    "        if column in [\"Departure station\", \"Arrival station\"] or \"comment\" in col_lower:\n",
    "            df[column] = (\n",
    "                df[column]\n",
    "                .fillna(\"\")\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .apply(lambda x: get_closest_match(x, clean_names))\n",
    "            )\n",
    "\n",
    "        # Dates au format YYYY-MM\n",
    "        elif \"date\" in col_lower:\n",
    "            df[column] = df[column].apply(lambda x: x if is_valid_date(x) else pd.NA)\n",
    "            df[column] = df[column].fillna(method='ffill')\n",
    "\n",
    "        # Service\n",
    "        elif column.lower() == \"service\":\n",
    "            df[column] = (\n",
    "                df[column]\n",
    "                .fillna(\"\")\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .apply(lambda x: x if x in [\"National\", \"International\"] else \"International\")\n",
    "            )\n",
    "        # Colonnes numÃ©riques\n",
    "        else:\n",
    "            try:\n",
    "                df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "                # Ca dÃ©gage toutes les valeurs < 0 Ã  0 (comptes & dÃ©lais)\n",
    "                df[column] = df[column].apply(lambda x: max(x, 0) if pd.notna(x) else 0)\n",
    "\n",
    "            except Exception as e:\n",
    "                if not e:\n",
    "                    print(e)\n",
    "                df[column] = df[column].fillna(\"\")\n",
    "\n",
    "    df = df.apply(fix_delay_consistency, axis=1)\n",
    "\n",
    "    # 4. Supprimer doublons (mÃªme dÃ©part/arrivÃ©e)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_program(df: pd.DataFrame):\n",
    "    data_values_dic = get_data_station(df)\n",
    "    data_values_tab = get_data_tab(df)\n",
    "    return data_values_dic, data_values_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Lecture du fichier csv\n",
    "    df = read_csv(\"dataset.csv\")\n",
    "\n",
    "    # Nettoyage du tableau\n",
    "    cleaned = clean_data(df)\n",
    "\n",
    "    # Convertir en csv\n",
    "    to_csv(cleaned, path=\"cleaned_dataset.csv\")\n",
    "\n",
    "    # RÃ©cupÃ©ration des donnÃ©es\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d480b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
